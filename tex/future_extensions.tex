\subsection{Machine Learning}

Currently, the algorithm uses a is purely mathematical approach to identify cattle. It extracts the edges from a muzzle image and generates a descriptor. Then, it uses brute force to find the closest match by minimizing the difference between descriptor. This method raises some rather serious challenges:

\begin{itemize}
	\item Some useful characteristics like eye colour and muzzle shape are being neglected. As humans, we instinctively use them to identify an individual. Hence, they could be used to further improve the efficiency and precision of our recognition algorithm. However, extracting and interpreting these features has proved to be difficult from an algorithmic point of view;
	\item The recognition algorithm does not perform a quality check of the images it processes. It assumes that the images uploaded are usable i.e. that the image always displays the muzzle of a cow clearly. But this is generally not the case. In practice, the muzzle might be wet or dirty or simply the image is blurred or of bad resolution. This makes the edge extraction less reliable and sometimes even impossible. A pure mathematical function, in essence, cannot deal with imperfect input that is beyond its input domain.\footnote{However we do have, to some extent, normalisation and correctional processes that de-skew and rotate the image.}
\end{itemize}

Nowadays, artificial intelligence techniques can be used to solve the challenges mentioned above. For example, we can use machine learning to identify a cattle in an image - just as we can using facial recognition on image of humans. Or, we can use it to outline an area of interest i.e. filtering out the parts that are not of interest to us.

The reason why we have not implement pushed our solution down this path is mainly because the size of our training data is too small. Unfortunately, we were given a very small reference dataset of which only ten were usable as training data. Obviously, this was not sufficient enough for us to train our algorithm to extract cattle features. Having said that, we have asked farmers to beta test our prototype and upload standardised muzzle images of their cattle. These photographs will ultimately be the foundation of our neural network.

\subsection{Integration with the Government Database}

As of now we require the farmer to upload the information of a cattle manually. This is a mundane and repetitive process and requires a lot of patience. To speed up the process and make it less error-prone, we want to integrate the system with the existing government database to allow the users to pull the data straight from the database without any manual input, provided that the users identity is verified and he/she has the permission to pull the requested cattle data.

Furthermore, we could allow users to push the (updated) information back into the government database for two-way synchronisation.

This process is not implementation intensive and can be done rather quickly. The only hinderance, is the government approval and support.

\subsection{Logging and Metrics}

We have built a system with a considerable number of complex components. It would be interesting to collect the running state of the whole system and individual components as well as collect diagnostic metrics. This would help us evaluate the efficiency and performance of our platform.

At the moment, the system only prints the log onto standard output. Fortunately, though, the standard output and standard error are captured by the Amazon services. This approach is fine for the very basic uses. However, problems appear when we try to filter/categorise the logs. For example, we might want to find the $k$ recent logs that belongs to the Persistent storage with the keyword $s$. The current approach would require a lot of mundane works including downloading the logs onto a machine that has Perl or other languages handy for text processing.

The metrics are not being collected at this point due to the extent of the project and the short amount of time we are given. However, this would be a lovely feature to have for performance analysis reasons. For instance, we would like to know how fast the algorithm runs for different types of images and what would possible be the causes that slow the process down. Also, if the algorithm is modified, we would like to know how these modifications affected performance as well as memory usage in comparison to its previous version.

The logging system should be fully equipped to do the basic and advanced data filtering and aggregation, preferably with charts and PDF reports. From past working experiences, we understand that there are already widely used and industrially accepted practices which we could easily deploy and use.

\subsection{Stereo Muzzle Reconstruction}

Our project uses the standard 2\-dimensional image matching technique. This is an acceptable practice. However, there are issues related to that:

\begin{itemize}
	\item Muzzles are not on a flat surface; in fact, like the earth, it is on rather bumpy and uneven surface. From a geometric point of view, any images we have taken are just a projection of that 3D surface onto a 2D plane, meaning that there will always be skewing to the original object given different angle or camera parameters. This would eventually introduce errors to the matching process.
	\item We have only taken one projected plane into consideration. To increase the accuracy, it might be of the best to not ignore any data useful for matching.
\end{itemize}

The mentioned issues can easily be resolved if we try and match based on 3D objects. Theoretically, with the right equipment, we would be able to reconstruct the muzzle. Widely used approaches include computational stereo and photometric stereo: the former reconstructs the desired object mathematically~\cite{computational_stereo} whereas the latter does it from illumination\footnote{However this is proven to be more difficult to use as 1) the technique would typically require the surface to be mostly Lambertian however the muzzles are mostly specular and 2) there are also strict requirements for the environmental lighting and camera and object angles across the views.}~\cite{photometric_stereo}.

The actual matching process, surprisingly, does not require a lot of tweaking to work. The key points are mathematically assumed to be $n$ dimensional, and so is the descriptor matcher (as the descriptor is essentially a $n$ dimensional matrix).
